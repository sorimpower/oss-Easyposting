<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title>jaso extends j2ee</title>
		<link>http://www.jaso.co.kr/</link>
		<description>김형준의 프로그램(J2EE)관련 블로그</description>
		<language>ko</language>
		<pubDate>Fri, 21 Mar 2014 11:06:55 +0900</pubDate>
		<generator>Textcube 1.5.4 : Fermata</generator>
		<item>
			<title>판교 벙개 3월 모임 후기</title>
			<link>http://www.jaso.co.kr/492</link>
			<description>3/20(목) 판교에서 벙개가 있었습니다. 모임 후기입니다.&lt;br /&gt;참석자는 그루터, 라인, 엔씨소프트, 카카오, 레드햇 이었습니다. SKT에서도 참석하셨는데 장애 문제로 바로 회사로 복귀하셔서 아쉬움이... 다과를 책임 지셨는데 무거운 손으로 오지도 못하고 돌아가신 분도 있었습니다.&lt;br /&gt;처음 주제는 Hadoop Tip, YARN 사용, 배포판 등에 대해서 이야기 하려고 했었는데 참석자 중 빅마우스에 의해 주제가 급 선회되어 NoSQL 어떤게 좋은가에 대한 피튀기는 토론을 진행했습니다.&lt;br /&gt;토론 대상이 된 솔루션은 HBase와&amp;nbsp; Cassandra 였습니다. 테스트 결과가 HBase, Cassandra 모두 TPS는 비슷하게 나오는데 Latency에서 Cassandra가 수 ms, 수십 ms, 수백 ms 대 이렇게 나누어져 나타나고 있다고 하였습니다. 왜 그렇게 나오는지에 대한 토론을 하면서 자연스럽게 그러면 HBase를 사용하는게 어떠냐 등등...&lt;br /&gt;정리하면 다음과 같습니다.&lt;br /&gt;&lt;br /&gt;- Cassandra&lt;br /&gt;&amp;nbsp;&amp;nbsp; 엄청 쉽다. 압축 플고 설정값 몇개만 바꾸고 실행하면 끝. &lt;br /&gt;&amp;nbsp;&amp;nbsp; 튜닝 파라미터가 있기는 한데 그 파라미터에 따라서 많이 좌우되지 않아서 좋다(즉, 기본 구성으로도 성능이 어느 정도 보장된다).&lt;br /&gt;&amp;nbsp;&amp;nbsp; 이전 버전에서는 장애나 장비 추가 시 데이터 리밸런싱에 문제가 있었지만 최근 버전에서는 조금씩 깔끔하게 잘 돌아간다.&lt;br /&gt;&amp;nbsp;&amp;nbsp; 중앙 집중적이지 않아 마스터서버와 같이 관리를 강화해야 하는 서버도 없다.&lt;br /&gt;- HBase&lt;br /&gt;&amp;nbsp; 많은 레퍼런스가 있다.&lt;br /&gt;&amp;nbsp; HDFS에서 많은 것을 해결해주고 HDFS는 검증이 되었기 때문에 HBase 자체만 보면 심플하다. 장애, 서버 추가시 등에서 Cassandra 대비 처리가 간단하다.&lt;br /&gt;&amp;nbsp; HDFS가 있는 상태라면 HBase이 더 좋지 않을까?&lt;br /&gt;&amp;nbsp; 분석 결과를 서비스해야 하는 경우에는 벌크 로드 기능이 있어 좋다&lt;br /&gt;&amp;nbsp; 서버 한대 장애시 failover 하는 동안에 대한 대책이 필요하다(캐쉬 등)&lt;br /&gt;&lt;br /&gt;이런 많은 이야기가 오고간 다음에 대략 HBase 를 사용하는 쪽으로 무게 중심이 많이 옮겨갔는데 결론은 내지 않았습니다.&lt;br /&gt;그리고 중간에 잠깐 그래프DB에 대해서도 나왔는데 titan(http://thinkaurelius.github.io/titan/), neo4j 등에 대한 기술적 내용과 네트워크 depth가 깊어지고 메모리 캐쉬가 miss 되는 경우 갑자기 느려진다 등과 같은 사용 사례에 대한 공유가 있었습니다.&lt;br /&gt;자유로운 이야기가 오고 가면서 많은 정보 교류와 서로간의 기술을 올리는 자리가 되었던것 같습니다.&lt;br /&gt;다음 모임을에는 사진이라도 한장 찍어야 겠네요. &lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>Dev_diary</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/492</guid>
			<comments>http://www.jaso.co.kr/492#entry492comment</comments>
			<pubDate>Fri, 21 Mar 2014 11:06:10 +0900</pubDate>
		</item>
		<item>
			<title>Tajo JDBC를 이용하여 R 연동</title>
			<link>http://www.jaso.co.kr/491</link>
			<description>Tajo JDBC를 이용하여 R을 연동해 보았습니다. 제대로 연동하려면 Tajo용 R 패키지를 만들어야겠지만 만들어지기 전에는 아쉬운대로 다음과 같이 사용하면 됩니다.&lt;br /&gt;&lt;br /&gt;- RJDBC 설치(&lt;a href=&quot;https://www.rforge.net/RJDBC/&quot; target=&quot;_blank&quot;&gt;https://www.rforge.net/RJDBC/&lt;/a&gt;)&lt;br /&gt;&lt;br /&gt;r shell을 실행하여 다음 명령 입력 (jar의 패스는 사용자 환경에 맞게 설정)&lt;br /&gt;&lt;br /&gt;library(RJDBC)&lt;br /&gt;cp &amp;lt;- c( &lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/hadoop-annotations-2.2.0.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/hadoop-auth-2.2.0.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/hadoop-common-2.2.0.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/hadoop-hdfs-2.2.0.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/joda-time-2.3.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/tajo-catalog-common-0.8.0-SNAPSHOT.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/tajo-client-0.8.0-SNAPSHOT.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/tajo-common-0.8.0-SNAPSHOT.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/tajo-jdbc-0.8.0-SNAPSHOT.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/tajo-rpc-0.8.0-SNAPSHOT.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/tajo-storage-0.8.0-SNAPSHOT.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/log4j-1.2.17.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/commons-logging-1.1.1.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/guava-11.0.2.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/protobuf-java-2.5.0.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/netty-3.6.2.Final.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/commons-lang-2.5.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/commons-configuration-1.6.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/slf4j-api-1.7.5.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/slf4j-log4j12-1.7.5.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/commons-cli-1.2.jar&quot;,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &quot;/Users/babokim/tmp/jdbc/commons-io-2.1.jar&quot; )&lt;br /&gt;&lt;br /&gt;.jinit(classpath=cp) &lt;br /&gt;drv &amp;lt;- JDBC(&quot;org.apache.tajo.jdbc.TajoDriver&quot;, &quot;/Users/babokim/tmp/jdbc/tajo-jdbc-0.8.0-SNAPSHOT.jar&quot;)&lt;br /&gt;conn &amp;lt;- dbConnect(drv, &quot;jdbc:tajo://127.0.0.1:26002&quot;, &quot;&quot;, &quot;&quot;)&lt;br /&gt;dbGetQuery(conn, &quot;select * from table1&quot;)&lt;br /&gt;&lt;br /&gt;R 패키지 만드는 법을 좀 익혀서 패스 등은 환경 변수로 받고 connection 등도 함수 호출이 되도록 구성해보겠습니다.&lt;br /&gt;&lt;br /&gt;위의 jar는 tajo JDBC 사용할 때 필요한 필수 jar 파일입니다. 참고하세요.&lt;br /&gt;tajo-jdbc-0.8.0-SNAPSHOT.jar 파일은 tajo maven 빌드하시면 다음 디렉토리에 있습니다.&lt;br /&gt;&amp;nbsp; &amp;nbsp; tajo-dist/target/tajo-0.8.0-SNAPSHOT/share/jdbc-dist/&lt;br /&gt;&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>Dev_diary</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/491</guid>
			<comments>http://www.jaso.co.kr/491#entry491comment</comments>
			<pubDate>Tue, 04 Mar 2014 18:10:37 +0900</pubDate>
		</item>
		<item>
			<title>Hadoop 몇가지 에러 로그 관련</title>
			<link>http://www.jaso.co.kr/490</link>
			<description>어제부터 오늘까지 Hadoop 로그로 저에게 확인 좀 해달라는 분이 계셔서 정리해 봤습니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;HDFS 클라이언트 측에서 다음과 같은 에러 발생&lt;/b&gt;&lt;br /&gt;상황은 Read가 계속 진행 중인 파일에 다른 클라이언트가 동시에 Append 할 경우 Read하는 클라이언트에서 다음 로그 발생(Hadoop 1.2.1 버전)&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;padding:10px; background-color:#E4E4E4&quot;&gt;14/02/26 22:17:20 WARN hdfs.DFSClient: Failed to connect to /xxx.xxx.xxx.xxx:50010 for file /aaa for block blk_1169180604221495865_65193:java.io.IOException: Got error for OP_READ_BLOCK, self=/xxx.xxx.xxx.xxx:60641, remote=/xxx.xxx.xxx.xxx:50010, for file /aaa , for block 1169180604221495865_65193&lt;br /&gt;14/02/26 22:17:20 WARN hdfs.DFSClient: Failed to connect to /xxx.xxx.xxx.xxx:50010 for file /aaa l for block blk_1169180604221495865_65193:java.io.IOException: Got error for OP_READ_BLOCK, self=/xxx.xxx.xxx.xxx:60642, remote=/xxx.xxx.xxx.xxx:50010, for file /aaa , for block 1169180604221495865_65193&lt;br /&gt;14/02/26 22:17:20 INFO hdfs.DFSClient: Could not obtain blk_1169180604221495865_65193 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...&lt;/div&gt;&lt;br /&gt;위 로그는 다음과 같은 이유때문에 발생&lt;br /&gt;Read를 위해 open 시에 namenode로 부터 block 10개의 정보를 가져옵니다. block 10개의 데이터를 모두 읽으면 다음 10개의 block 정보를 가져와서 읽는 방식입니다.&lt;br /&gt;여기서 append 하는 클라이언트 append mode로 오픈을 하게 되면 namenode에서는 마지막 block을 under construction으로 바꾸게 됩니다. 그리고 datanode에서는 namenode와 통신을 통해 마지막 block의 seq 를 하나 증가시킵니다.&lt;br /&gt;이 상태에서 read 하는 client가 마지막 block까지 가게 되면 이 정보는 append가 발생하기 이전에 가져온 정보이기 때문에 seq가 맞지 않아 DataNode에서는 에러를 발생시킵니다.&lt;br /&gt;읽기 client는 이런 상황이 발생하면 다시 namenode로 부터 block 정보를 가져오고 under construction 상태이면 마지막 block에 정보는 DataNode로 부터 다시 가져와서( DataNode의 getBlockInfo() 메소드 호출) block 정보를 수정한 다음에 읽기 작업을 계속합니다. &lt;br /&gt;로그를 자세히 보시면 로그 레벨이 ERROR이 아니라 WARN인 것을 볼 수 있습니다. 그리고 마지막에 &quot;Will get new block locations from namenode and retry&quot; 이런 문구도 있고요. 즉 실제 읽기는 문제없이 잘 돌아갈 것으로 생각됩니다. 단, 마지막 block 정보를 가져온 다음에 append 된 데이터는 가져오지 못합니다&lt;br /&gt;&lt;br /&gt;&lt;b&gt;로그 레벨을 DEBUG로 할 경우 다음과 같은 debug 로그 발생&lt;/b&gt;(Hadoop 2.2.0)&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;padding:10px; background-color:#E4E4E4&quot;&gt;DEBUG: Error making BlockReader. Closing stale&lt;br /&gt;&amp;nbsp; java,io.EOFException: Premature EOF: no length prefix available&lt;/div&gt;&lt;br /&gt;이것은 HDFS 클라이언트에서 성능 향상을 위해 DataNode로 접속(Socket Connection)을 일정 시간동안은 캐쉬하고 있는데 이 캐쉬가 expire되어 connection은 닫혔는데 다시 사용할 경우 발생하는 로그로 클라이언트 내부 코드에 의해 자동 재 접속하기 때문에 성능상, 기능상 문제가 없습니다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;DataNode에서 다음과 같은 에러메시지가 무지 많이 나옴&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;padding:10px; background-color:#E4E4E4&quot;&gt;ERROR: ....&lt;br /&gt;java.io.IOException: 연결이 상대편에 의해 끊어짐&lt;/div&gt;&lt;br /&gt;이것이 좀 황당한 경우인데 이 에러가 발생하는 원인은 DataNode로 읽기 요청을 한 이후 정상 close() 방식이 아닌 강제로 종료된 경우 DataNode에서는 데이터를 보낼 연결이 종료되었기 때문에 발생합니다.&lt;br /&gt;문제는 이것은 DataNode 입장에서는 정상적인 상황이라서 ERROR 레벨로 출력하면 안되는 메시지입니다. 실제 코드에서는 다음과 같이 되어 있습니다.&lt;br /&gt;&lt;br /&gt;String ioem = e.getMessage();&lt;br /&gt;if (!ioem.startsWith(&quot;Broken pipe&quot;) &amp;amp;&amp;amp; !ioem.startsWith(&quot;Connection reset&quot;)) {&lt;br /&gt;&amp;nbsp; LOG.error(&quot;BlockSender.sendChunks() exception: &quot;, e);&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;즉 에러 메시지 중 Broken pipe, Connection reset 은 무시하겠다는 건데 JVM 실행환경이 한글 환경이라서 에러 메시지도 한글(&quot;연결이 상대편에 의해 끊어짐&quot;)로 나왔기 때문에 출력되는 겁니다. 즉 무시해도 되는 에러이고 JVM 언어 설정을 utf8 등으로 변경하면 나타나지 않을 에러입니다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>Dev_diary</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/490</guid>
			<comments>http://www.jaso.co.kr/490#entry490comment</comments>
			<pubDate>Thu, 27 Feb 2014 12:37:47 +0900</pubDate>
		</item>
		<item>
			<title>실시간 분석 플랫폼 관련 판교 벙개</title>
			<link>http://www.jaso.co.kr/489</link>
			<description>지난 2/19 실시간 분석 플랫폼 관련해서 판교에서 벙개가 있었습니다.&lt;br /&gt;여러 회사(라인, 카카오, 그루터,&amp;nbsp; SKC&amp;amp;C, nflabs)에서 실제 경험이 있으신 분들이 오셔서 재미있는 토론을 했습니다. 간단하게 정리하면 다음과 같습니다.&lt;br /&gt;&lt;br /&gt;1.&amp;nbsp; Storm의 Guaranteed message 동작원리&lt;br /&gt;&amp;nbsp; &amp;nbsp; . Ack, Fail Signal을 어떻게 전달하는지에 대한 동작원리?&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; -&amp;gt; 사용은 하지만 정확하게 동작원리는 모른다.&lt;br /&gt;&amp;nbsp; &amp;nbsp; . Guaranteed message을 이용하는 것은 중복은 허용하지만 유실은 없도록 하는 것에 촛점을 맞추고 있다.&lt;br /&gt;&lt;br /&gt;2. Storm 동작원리 분석이 어렵다.&lt;br /&gt;&amp;nbsp;&amp;nbsp; -&amp;gt; clojure로 되어 있어 코드 분석하기가 어렵다.&lt;br /&gt;&lt;br /&gt;3. Storm을 반드시 사용해야 하는가?&lt;br /&gt;&amp;nbsp;&amp;nbsp; -&amp;gt; 정확한 동작원리도 이해가 안된 상태이고 Storm을 사용하더라도 개발자가 만들어야 하는 것이 너무 많다.&lt;br /&gt;&amp;nbsp;&amp;nbsp; -&amp;gt; 그렇지만 Spout, Blot 장애시 자동으로 재시작해주는 기능(안정성)과 Kafka와 궁합이 잘맞기 때문에 사용한다.&lt;br /&gt;&lt;br /&gt;4. 다른 아키텍처는 없나?&lt;br /&gt;&amp;nbsp;&amp;nbsp; -&amp;gt;&amp;nbsp; Spark를 이용하여 time window내의 데이터를 spark에 넣고 질의를 이용하여 분석한 후 분석이 완료된 데이터는 메모리에서 없애는 방법&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 이 방법은 이미 사용하고 있는 회사가 있으며 문제는 spark의 안정성에 문제가 있다. Spark 초창기 버전부터 사용했는데 초창기에는 많은 문제가 있어 질의가 실행이 안되거나 drop table을 해도 메모리 해제가 안되는 경우가 많았다. 최신 버전에서 이런 문제가 얼마나 해결되었는지는 반드시 검토해봐야 한다.&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp; -&amp;gt; 그런 관점이라면 Splunk도 좋은 대안이 되지 않나. Splunk를 대용량 분석 용도로 사용하기 보다는 최근 몇분 또는 몇시간 이내의 데이터만 분석하는 실시간 분석 용도로 사용&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; 이 방법도 좋은 방법이지만 비용 등의 문제&lt;br /&gt;&amp;nbsp;&amp;nbsp; -&amp;gt; Elastic Search를 이용하는 방법은 어떤가?&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; Splunk와 유사한 방식으로 구성하고 실시간 분석이기 때문에 많은 양의 데이터를 저장할 필요도 없기 때문에 잘 구성만 하면 좋은 아키텍처가 될 수 있을 듯.&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; 사용자 친화적인 SQL 비슷한 형태의 질의 기반으로 분석할 수 있는 기능을 제공하면 좋을 듯&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; facet 기능 등을 이용하여 group by 등도 쉽게 처리 가능. JOIN 등의 복잡한 질의에 성능이 나올지는 좀 더 검토 필요&lt;br /&gt;&lt;br /&gt;대략 이정도 이야기가 나왔습니다. 여러 회사 또는 개인적인 경험들을 공유할 수 있어어 좋은 자리였습니다.&lt;br /&gt;지금까지의 기술교류가 대부분 세미나 중심이었는데 세미나는 일방향적으로 커뮤니케이션이 일어나고 깊은 내용을 다루기에는 어려움이 있었습니다. 앞으로는 이런 방식의 기술 공유 자리를 많이 만들어 볼까 합니다.&lt;br /&gt;다음에는 어떤 주제로 어느 지역에서 할지....&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>Dev_diary</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/489</guid>
			<comments>http://www.jaso.co.kr/489#entry489comment</comments>
			<pubDate>Thu, 20 Feb 2014 15:58:23 +0900</pubDate>
		</item>
		<item>
			<title>YARN에서 MapReduce 관련 옵션</title>
			<link>http://www.jaso.co.kr/488</link>
			<description>YARN은 Hadoop2의 가장 대표적인 기능중에 하나이지만 개념적으로 환경설정, 튜닝 등의 이슈들이 아직 많이 공유되지 않아서 실제 사용 클러스터에서는 많이 사용하지 않는 것 같다. &lt;br /&gt;CDH 버전이 많이 배포되는 이유도 Hadoop 2.0 이상에서만 지원되는 HDFS의 NameNode 이중화는 사용하고 싶고 MR은 기존 방식인 MR1을 사용하고자 하는 사용자의 요구사항에 CDH 배포판이 딱 맞아 떨어지기 때문이 아닌가 생각한다.&lt;br /&gt;&lt;br /&gt;YARN 환경 설정 관련해서 대략 다음과 같은 파라미터 설정이 필요하다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;yarn-site.xml&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Shuffle 관련 설정:&amp;nbsp; YARN 기반인 경우 NodeManager에 Task만 실행되고 중지되어 버리기 때문에 MapTask의 결과가 ReduceTask로 전달되기 위해서는 ReduceTask로부터의 Map 결과 데이터 전송 요청에 응답해서 데이터를 전송하는 데몬이 필요하다. YARN에서는 이런 종류의 데몬을 위해 각 Application(JOB)별로 각 NodeManager에 하나씩 지정한 프로그램을 실행하는 기능을 제공한다. 이런 서비스를 auxiliary service 라고 부른다.&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;각 NodeManager는 Container 할당에 사용할 메모리 사이즈를 지정해야 한다. 여기서 설정된 값은 JVM의 heap 사이즈를 넘어서 설정하지 않는다. NodeManager의 JVM의 heap 사이즈는 etc/hadoop/yarn-env.sh에서 &quot;export YARN_NODEMANAGER_HEAPSIZE=8096&quot; 와 같이 설정한다.&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;lt;name&amp;gt;yarn.nodemanager.resource.memory-mb&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;lt;value&amp;gt;8000&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;ResourceManager는 하나의 container에 할당할 수 있는 메모리 min/max 값을 설정해야 한다.&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;512&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;yarn.scheduler.maximum-allocation-mb&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;2048&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;YARN으로 실행 시 JobTracker가 없기 때문에 MR Job이 종료된 이후에도 작업 실행 정보와 로그 정보를 보기 위해서는 MR History Server를 실행해야 한다. 이 서버를 실행한다고 해서 작업 목록이 보이지 않는데 다음과 같이 log aggregation 옵션을 true로 해야 한다.&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;mapred-site.xml&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;JobTracker, TaskTracker는 없어졌지만 JobClient가 사용하는 환경설정을 해야 하는데 기존과 동일하게 mapred-site.xml 파일에 설정한다.&lt;br /&gt;처음 테스트 환경에 설치했을 때 가장 많은 어려움을 겪는 설정인데 하나의 MapReduce JOB(YARN의 개념으로는 Application)을 실행하면 YARN Application Master가 실행되고 이 Application Master에 의해 Container가 할당되어 실행되는 방식이다. 다음 설정은 Application Master에 대한 Container의 메모리 설정 정보이다. 기본값이 1536으로 1.5GB이다.&amp;nbsp; 이 설정 값과 &quot;yarn.scheduler.maximum-allocation-mb&quot; 설정이 맞지 않으면 다음과 같은 에러 메시지가 나타난다.&lt;br /&gt;&lt;br /&gt;Invalid resource request, requested memory &amp;lt; 0, or requested memory &amp;gt; max configured, requestedMemory=1536, maxMemory=512&lt;br /&gt;&lt;br /&gt;이 메시지에서 requestedMemory의 의미는 MR Job을 위한 Application Master Container를 위한 메모리이고 maxMemory는 yarn.scheduler.maximum-allocation-mb 값이다. 즉 yarn.app.mapreduce.am.resource.mb 설정 값은 반드시 yarn.scheduler.maximum-allocation-mb 값보다는 작아야 한다.&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;yarn.app.mapreduce.am.resource.mb&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;512&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;기본 설정 값에서 Map/Reduce Task는 각각 1GB의 Container를 요청한다. 클러스터에 따라 이 값이 너무 클수도 있는데 다음 설정 값으로 변경한다.&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;mapreduce.map.memory.mb&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;512&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;&amp;lt;property&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;name&amp;gt;mapreduce.reduce.memory.mb&amp;lt;/name&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;value&amp;gt;512&amp;lt;/value&amp;gt;&lt;br /&gt;&amp;lt;/property&amp;gt;&lt;br /&gt;&lt;br /&gt;테스트 환경에서는 메모리 크기가 크지 않기 때문에 메모리 사이즈 설정을 잘해야 하는데 가장 간단한 MapReduce를 실행하기 위해서는 Container 3개가 필요하다. NodeManager의 yarn.nodemanager.resource.memory-mb 설정 값의 합이 yarn.app.mapreduce.am.resource.mb, mapreduce.map.memory.mb, mapreduce.reduce.memory.mb의 합보다 커야 한다.&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>lucene_hadoop</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/488</guid>
			<comments>http://www.jaso.co.kr/488#entry488comment</comments>
			<pubDate>Wed, 22 Jan 2014 18:40:32 +0900</pubDate>
		</item>
		<item>
			<title>개발 프로젝트는 섬세해야 한다.</title>
			<link>http://www.jaso.co.kr/486</link>
			<description>필자는 백명 이상 투입된  큰 SI 프로젝트부터 수천만명 이상의 사용자가 사용하는 포털의 서비스 개발 프로젝트, 1 ~ 2명이 개발하는 작은 단위릐 프로젝트까지 아주 다양한 유형의 프로젝트에 참여해 보았다. &lt;br /&gt;참여한 대부분의 프로젝트의 과제 기획부터 관리, 운영에 이르기까지 개발자 중심으로 운영되는 프로젝트는 거의 없었다. 그나마 개발자의 의견이 많이 반영되거나 개발자가 직접 관리 또는 의사결정하는 경우는 포털의 서비스 개발 및 운영에서가 유일했던 것 같다.&lt;br /&gt;필자는 뼈속까지 개발자이다. 모든 개발자가 필자와 같은 생각이나 감정, 느낌을 가지고 있지는 않겠지만 만나본 많은 개발자들은 섬세하고, 민감하다. 특히 자신이 만들고 있는 프로그램과 관련된 일인 경우에는 그런 성향이 더 뚜렷하다.&lt;br /&gt;잠깐 필자의 예를 들어 개발자들의 성향을 보면 다음과 같은 특징들이 있다(지극히 개인적인 생각이며 반론이 있으신 분은 댓글로 의견 제시해주세요.)&lt;br /&gt;&lt;br /&gt;- 자기 방어적&lt;br /&gt;자신이 만든 프로그램이 잘못된 경우 많은 프로젝트에서는 개발자의 잘못으로 돌리는 경우가 많고 책임도 개발자에게 넘기려는 경우도 많다. 따라서 개발자는 무엇이 잘못되었다라는 지적에 대해 상당한 과민 반응을 보이고 자기 잘못이 아니라는 것을 증명하려고 노력한다. 이런 태도로 인해 문제가 발생할 가능성이 많은 새로운 기능 등의 추가에 대해서 수동적인 자세를 많이 가진다. 이런 성향은 개발자가 원래 그런것이 아니라 사회적, 조직적으로 그렇게 결론을 내기 때문에 나타나는 성향이라 볼 수 있다.&lt;br /&gt;&lt;br /&gt;- 단순&lt;br /&gt;개발자는 복잡한 문제를 해결하는데 집중하지만 실제로 사람과의 관계, 비즈니스 관계, 사내 정치적인 관계에 대해서는 순진할 정도로 단순한 생각을 가진다. 복잡한 이해관계속에서 나에게 어떤것이 이득이 될 것인가 등과 같은 생각을 잘 하지 않는다.&lt;br /&gt;&lt;br /&gt;- 논리적&lt;br /&gt;프로그램이라는 것 자체가 논리적인 연산의 반복이기 때문에 이것을 만드는 개발자 역시 사고가 논리적일 수밖에 없다. 따라서 어떤 경우에는 비논리적인 이슈로 의사결정이 이루어지는 프로젝트 기획, 관리, 영업 등의 행위를 이해 못하는 경우가 많다.&lt;br /&gt;&lt;br /&gt;- 애착&lt;br /&gt;자기가 만든 프로그램 또는 서비스 등에 애착을 많이 가지고 있다. 어떤 경우에는 프로그램을 만들거나 서비스를 개선하는 것이 회사일이 아니라 자신의 애완견을 돌보거나 심지어는 자식을 돌보는 것처럼 생각하는 경우도 있다.&lt;br /&gt;&lt;br /&gt;- 얼리어탭터&lt;br /&gt;필자의 경우는 그렇지 않지만 많은 개발자들은 새로 나온 디지털 디바이스나 서비스 등에 열광한다. 즉 새로운 것을 받아 들이는데 거부감이 별로 없다.&lt;br /&gt;&lt;br /&gt;- 자기주도적&lt;br /&gt;개발자들을 수동적인 성향이 많다고 이야기들하는데 잘못된 부분이라고 생각한다. 수동적인 이유는 첫번째에서 말한 &quot;자기방어적&quot;이기 때문이다. 개발자는 원래 자기주도적이다. 문제만 던져주면 스스로 해결책을 찾아서 풀려고 노력하는 몇 안되는 직업중의 하나이다.&lt;br /&gt;&lt;br /&gt;흔히 기획자나 관리자들은 많은 개발자들이 커뮤니케이션에 서툴다고 생각하고 있다. 기획자나 관리자들이 커뮤니케이션에 문제가 많다고 생각하는 개발자도 의외로 프로젝트 내에서의 개발자들 사이에는 많은 커뮤니케이션을 하면서 문제없이 프로그램을 잘 만들어 내는 개발자도 많다. &lt;br /&gt;개발자들이 커뮤니케이션을 잘 못한다는 것은 개발자의 이러한 특징이나 감정적인 성향을 이해하지 못하는데서 오는 오해인 경우도 많다고 필자는 생각한다.&lt;br /&gt;&lt;br /&gt;필자가 &quot;개발 프로젝트에서 가장 중요한 요소는 무엇인가?&quot;라는 질문을 받으면 생각해볼 여지 없이 &quot;실제 프로그램을 만들어 내는 개발자&quot; 라고 답할 것이다. 하지만 대부분의 프로젝트는 기획 단계부터 철저하게 개발자의 일반적인 성향, 감정, 의사소통 등에 대해서는 전혀 고려하지 않는다. &lt;br /&gt;프로젝트 팀 구성, 과제 목표, 과제의 분리, 과제의 관리자, KPI 선정 등에 있어 개발자에 대한 고려는 전혀 없다. 누구나 데려와서 시키면 다 할 수 있다는 전제하에 기획을 한다. 이 단계에서 부터 많은 프로젝트는 이미 어긋나 있는 것이다. &lt;br /&gt;이글을 쓰는 계기가 된 프로젝트 과제 기획건의 예를 들면 다음과 같은 사례가 있다. A라는 과제를 기획하면서 과제의 목표, 투입될 개발자 등에 대해 정의가 되었고 아주 잘 진행이 될 것 같았다. 하지만 다른 과제 B를 기획하는 측에서 A과제의 많은 부분을 사용해야 하고 과제 B의 규모가 더 크기 때문에 과제 A를 과제 B에 넣어서 프로젝트의 관리, 프로젝트 목표 등을 B 과제와 연동하게 하는 기획안을 들고 왔다. &lt;br /&gt;필자는 이 기획안대로 할 경우 과제 A는 실패할 가능성이 높다고 반대 의견을 제시했다. 이유는 과제 A와 과제 B는 서로 다른 성격의 개발 프로세스와 관리가 되어야 함에도 불구하고 비슷하다는 이유와 기획/관리의 편의성 때문에 묶어서 진행할 경우 많은 문제가 발생하기 때문이다. 가장 대표적인 문제가 과제 A의 개발자들의 태도이다. 이들의 태도가 바뀌면 태도가 수동적으로 바뀌고 이렇게 되면 다시 관리자가 섬세하게 개입해야 한다. 어떤 관리자도 개발자가 만들어야 하는 모든 항목에 대해 관리를 할 수 없을 것이다. 많은 부분을 개발자가 스스로 할 수 있도록 해야 하는데 그런 분위기를 만들지 못하면 과제 A는 실패할 가능성이 높다. 과제 A가 실패하면 과제 B도 실패이다. &lt;br /&gt;문제는 대부분의 경우 이런 의견은 무시된다. 개발자들은 단순한 부속품으로 생각하는 경우가 많기 때문이다. 그들의 감정과 동기부여 등에는 관심 없다.&lt;br /&gt;&lt;br /&gt;또 넘어야 할 산은 기획 단계를 넘어 프로젝트 진행 단계에서의 프로젝트 관리자에게 있다. 대부분의 프로젝트 관리자는 개발자가 아니거나 대기업 SI 업체에서 대리 중반정도(5 ~ 6년차)까지만 개발하고 프로젝트 기획 등의 과정을 거쳐 프로젝트 관리자 역할을 수행하는 경우가 많다. 이런 관리자는 개발자의 이런 성향을 이해하고 관리에 활용하지 못한다. 단순히 프로젝트 진행 외적으로 보이는 부분을 가지고 관리를 하려고 한다. &lt;br /&gt;일부 관리자들 중에 개발자의 성향을 이해하고 있다 하더라고 애초 프로젝트 기획의 문제나 다른 문제로 인해 그런 눈에 보이지 않는 위험은 무시하려고 한다. 눈에 보이지 않기 떄문에 관리도 어렵고 그런 관리가 잘못될 경우 표현할 방법과 수치화 시키기 어렵기 때문일 것이다.&lt;br /&gt;이런 이유들 때문에 프로젝트에 투입된 개발자는 행복하지 않다. 실제 제품을 만들어내는 주체가 행복하지 않는데 어떻게 좋은 제품이 나오겠는가? 제조업이면 정해진 스펙대로만 만들면 설계된 수준의 품질이 나온다. 하지만 프로그램은 똑같은 결과를 만들어 내기 위한 방법이 무한대로 있고 각각의 개발자는 자신만의 방법으로 문제를 풀어 나간다.&lt;br /&gt;많은 개발 방법론이 있고 지금도 새로운 방법론이 나오고 있고 각 개발 조직에서는 어떤 개발 방법이 자신의 조직이나 환경에 최적인지 찾기 위한 연구를 하고 있고 있다.&lt;br /&gt;하지만 필자가 생각하는 가장 좋은 개발 방법론은 개발자를 위한 방법론이라고 생각한다. 개발자가 과제를 수행하는데 어떤 불편함이 예상되고 이를 어떻게 해결할 것인가? 최적의 개발 환경을 어떻게 구성할 수 있을 것인가? 어떻게 개발자들에게 동기 부여를 할 수 있을 것인가? 이런 고민을 잘 해결하는 것이 최고의 방법론이 아닌가 생각한다.&lt;br /&gt;&lt;br /&gt;개발자들의 감정은 단순하지만 그들이 만드는 프로그램에 대해서는 섬세할 정도로 예민한 감성을 가지고 있습니다. &lt;br /&gt;우리를 조금이나마 이해하는 과제가 많이 나왔으면 하는 마음에 일요일 까페에서 혼자 시간이 남아 두서없이 몇자 적어 보았습니다.&lt;br /&gt;&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>Dev_diary</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/486</guid>
			<comments>http://www.jaso.co.kr/486#entry486comment</comments>
			<pubDate>Sun, 19 Jan 2014 10:44:44 +0900</pubDate>
		</item>
		<item>
			<title>Impala TPC-DS 성능 테스트 결과 의견</title>
			<link>http://www.jaso.co.kr/485</link>
			<description>최근 Cloudera에서 Impala와 Hive, 분산DBMS와 테스트를 한 블로그가 올라 왔습니다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2014/01/impala-performance-dbms-class-speed/&quot; target=&quot;_blank&quot;&gt;Impala Performance Update: Now Reaching DBMS-Class Speed&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;이 자료를 처음 보고 놀란 것은 3TB 데이터를 5대의 DataNode로 질의가 대부분 10 ~ 20초 사이에 실행되고 있는 결과 그래프였습니다. &lt;br /&gt;단순히 이 그래프의 수치만 믿고 Impala를 도입해야 겠다거나 &quot;Impala 열라 빠르더라&quot; 라고 보편적으로 이야기할 분들이 계실 것 같았습니다. 하지만 조금만 생각해보면 이 수치는 일반적인 SATA 디스크의 물리적인 한계를 뛰어넘는 수치입니다. 그래서 좀 자세하게 확인해 보았습니다.&lt;br /&gt;&lt;br /&gt;다음과 사이트에 테스트한 스크립트가 있습니다.&lt;br /&gt;&lt;a href=&quot;https://github.com/cloudera/impala-tpcds-kit&quot; target=&quot;_blank&quot;&gt;https://github.com/cloudera/impala-tpcds-kit&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&amp;nbsp;TPC-DS는 store_sales 테이블이 fact 테이블(큰 사이즈의 테이블)이고 나머지 테이블은 모두 demision 테이블(작은 사이즈 테이블)입니다.&lt;br /&gt;&lt;br /&gt;이중 q19는 다음과 같습니다.&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;font-family: Consolas, &#039;Liberation Mono&#039;, Courier, monospace; font-size: 12px; margin-top: 0px; margin-bottom: 0px; color: rgb(51, 51, 51); font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 18px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;&quot;&gt;&lt;div class=&quot;line&quot; id=&quot;LC2&quot; style=&quot;padding-left: 10px;&quot;&gt;&lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;select&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC3&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_brand_id&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;brand_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC4&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_brand&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;brand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC5&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manufact_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC6&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manufact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC7&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ss_ext_sales_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ext_price&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC8&quot; style=&quot;padding-left: 10px;&quot;&gt;&lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;from&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC9&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;date_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC10&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;store_sales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC11&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC12&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC13&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;customer_address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC14&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;store&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC15&quot; style=&quot;padding-left: 10px;&quot;&gt;&lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;where&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC16&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;d_date_sk&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ss_sold_date_sk&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC17&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ss_item_sk&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_item_sk&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC18&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manager_id&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;7&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC19&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;d_moy&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;11&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC20&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;d_year&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;1999&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC21&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ss_customer_sk&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;c_customer_sk&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC22&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;c_current_addr_sk&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ca_address_sk&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC23&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ca_zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;s_zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC24&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ss_store_sk&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;s_store_sk&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC25&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ss_sold_date_sk&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;between&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;2451484&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;2451513&lt;/span&gt;  &lt;span class=&quot;c1&quot; style=&quot;color: rgb(153, 153, 136); font-style: italic;&quot;&gt;-- partition key filter&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC26&quot; style=&quot;padding-left: 10px;&quot;&gt;&lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;by&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC27&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_brand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC28&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_brand_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC29&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manufact_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC30&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manufact&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC31&quot; style=&quot;padding-left: 10px;&quot;&gt;&lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;by&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC32&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;ext_price&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC33&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_brand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC34&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_brand_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC35&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manufact_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC36&quot; style=&quot;padding-left: 10px;&quot;&gt;&amp;nbsp; &lt;span class=&quot;n&quot; style=&quot;color: rgb(51, 51, 51);&quot;&gt;i_manufact&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot; id=&quot;LC37&quot; style=&quot;padding-left: 10px;&quot;&gt;&lt;span class=&quot;k&quot; style=&quot;font-weight: bold;&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;color: rgb(0, 153, 153);&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;br /&gt;아주 큰 테이블인 store_sales 테이블과 다양한 디멘젼 테이블간의 join과 where 조건에 filter 조건이 있습니다. where 절에서 year, month로 filter를 걸고 있는데 이것때문에 partition이 적용되어 실제 scan은 3TB가 아니라 아주 작은 양의 데이터만 스캔했기 때문에 그런 수치가 나왔을 거라 추측해봅니다.&lt;br /&gt;다음은 store_sales 테이블의 테이블 생성 스크립트입니다. date로 파티션되어 있는 것을 볼 수 있습니다.&lt;br /&gt;&lt;br /&gt;create table store_sales&lt;br /&gt;(&lt;br /&gt;&amp;nbsp; ss_sold_time_sk int,&lt;br /&gt;&amp;nbsp; ss_item_sk int,&lt;br /&gt;&amp;nbsp; ss_customer_sk int,&lt;br /&gt;&amp;nbsp; ss_cdemo_sk int,&lt;br /&gt;&amp;nbsp; ss_hdemo_sk int,&lt;br /&gt;&amp;nbsp; ss_addr_sk int,&lt;br /&gt;&amp;nbsp; ss_store_sk int,&lt;br /&gt;&amp;nbsp; ss_promo_sk int,&lt;br /&gt;&amp;nbsp; ss_ticket_number int,&lt;br /&gt;&amp;nbsp; ss_quantity int,&lt;br /&gt;&amp;nbsp; ss_wholesale_cost double,&lt;br /&gt;&amp;nbsp; ss_list_price double,&lt;br /&gt;&amp;nbsp; ss_sales_price double,&lt;br /&gt;&amp;nbsp; ss_ext_discount_amt double,&lt;br /&gt;&amp;nbsp; ss_ext_sales_price double,&lt;br /&gt;&amp;nbsp; ss_ext_wholesale_cost double,&lt;br /&gt;&amp;nbsp; ss_ext_list_price double,&lt;br /&gt;&amp;nbsp; ss_ext_tax double,&lt;br /&gt;&amp;nbsp; ss_coupon_amt double,&lt;br /&gt;&amp;nbsp; ss_net_paid double,&lt;br /&gt;&amp;nbsp; ss_net_paid_inc_tax double,&lt;br /&gt;&amp;nbsp; ss_net_profit double&lt;br /&gt;)&lt;br /&gt;&lt;b&gt;&lt;font color=&quot;#FF0000&quot;&gt;partitioned by (ss_sold_date_sk int)&lt;/font&gt;&lt;/b&gt;&lt;br /&gt;stored as parquetfile&lt;br /&gt;;&lt;br /&gt;&lt;br /&gt;질의를 보면 sales_store의 ss_sold_date_sk 필드에 대해 where 조건에 filter가 없고 date_dim 테이블에 대해서만 filter가 있고 다시 date_dim과 sales_store 테이블의 ss_sold_date_sk 필드로 join하고 있기 때문에 plan을 잘 세우면 파티션만 스캔할 수 있도록 가능합니다. Impala의 경우 이런 부분까지 파티션을 인식할 수 있도록 plan을 잘 잡고 있는 것 같습니다.&lt;br /&gt;Impala의 옵티마이저가 나름 똑똑해서 파티션 인식은 잘하지만 공개한 블로그의 데이터 크기를 그대로 믿고 현장에 적용할 경우 낭패를 볼 수 있을 것 같습니다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>lucene_hadoop</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/485</guid>
			<comments>http://www.jaso.co.kr/485#entry485comment</comments>
			<pubDate>Tue, 14 Jan 2014 12:04:51 +0900</pubDate>
		</item>
		<item>
			<title>최근 Data 처리 관련 오픈소스</title>
			<link>http://www.jaso.co.kr/484</link>
			<description>벌써 2014이 일주일 지났는데 올해 무엇을 할지 계획도 못 세웠습니다. 그래도 대략 정리는 해야 할 것 같아서 최근 출시되거나 관심을 받고 있는 데이터 처리 플랫폼에 대해 정리해 보았습니다.&lt;br /&gt;&lt;br /&gt;Acculumo&lt;br /&gt;&lt;a href=&quot;http://accumulo.apache.org/&quot; target=&quot;_blank&quot;&gt;http://accumulo.apache.org&lt;/a&gt;&lt;br /&gt;HBase와 유사한 시스템으로 HDFS에 데이터 파일을 저장하는 Key/Value Store로 NSA에서 개발되어 현재는 apache 프로젝트로 공개&lt;br /&gt;&lt;br /&gt;Samza&lt;br /&gt;&lt;a href=&quot;http://samza.incubator.apache.org&quot; target=&quot;_blank&quot;&gt;http://samza.incubator.apache.org&lt;/a&gt;&lt;br /&gt;&amp;nbsp;LinkedIn에서 개발한 Storm과 비슷한 플랫폼으로 Kafka, YARN 등을 사용하여 스트리밍 프로세싱을 지원하는 플랫폼&lt;br /&gt;&lt;br /&gt;Tajo&lt;br /&gt;&lt;a href=&quot;http://tajo.incubator.apache.org&quot; target=&quot;_blank&quot;&gt;http://tajo.incubator.apache.org&lt;/a&gt;&lt;br /&gt;SQL을 이용하여 HDFS에 저장된 데이터를 빠르게 처리할 수 있는 기능을 제공하는 SQL-On-Hadoop 계열의 플랫폼으로 ETL 작업과 같은 데이터가 크고 작업 시간이 긴 질의과 Interactive Analystic 작업과 같이 빠른 응답성이 필요한 질의 모두들 만족시키는 플랫폼. 고려대학교 데이터베이스랩에서 최초 개발하였으며 최근에는 그루터와 SKT에서 주로 Contribution 하고 있음.&lt;br /&gt;&lt;br /&gt;Suro&lt;br /&gt;&lt;a href=&quot;https://github.com/netflix/suro&quot; target=&quot;_blank&quot;&gt;https://github.com/netflix/suro&lt;/a&gt;&lt;br /&gt;비디오 스트리밍 서비스로 유명한 netflix에서 개발한 솔루션으로 데이터 수집을 지원하는 플랫폼이다. Yahoo에서 개발했던 Chukwa을 기본으로 많은 부분을 수정하여 Suro를 만들었다고 함.&lt;br /&gt;&lt;br /&gt;Tez&lt;br /&gt;&lt;a href=&quot;http://tez.incubator.apache.org&quot; target=&quot;_blank&quot;&gt;http://tez.incubator.apache.org&lt;/a&gt;&lt;br /&gt;YARN 위에 작업을 실행하는 Task를 directed-acyclic-graph로 배치하고 관리할 수 있는 기능을 제공하는 플랫폼으로 Hive의 개선 버전인 Stinger의 분산 플랫폼 엔진으로 사용될 예정.&lt;br /&gt;&lt;br /&gt;Spark&lt;br /&gt;&lt;a href=&quot;http://spark.incubator.apache.org&quot; target=&quot;_blank&quot;&gt;http://spark.incubator.apache.org&lt;/a&gt;&lt;br /&gt;버클리의 Amplab에서 만들어서 apache에 기증한 플랫폼으로 HDFS에 저장된 데이터를 분산된 한번만 로딩한 후 데이터 분석 작업 시에는 메모리에 있는 데이터를 이용함으로써 빠르게 분석하는 것을 목표로 만든 시스템이다. 주로 Spark위에서 SQL을 실행하게 하는 Shark와 같이 사용한다.&lt;br /&gt;&lt;br /&gt;Ankus&lt;br /&gt;&lt;a href=&quot;http://www.openankus.org&quot; target=&quot;_blank&quot;&gt;http://www.openankus.org&lt;/a&gt;&lt;br /&gt;MapReduce를 이용한 data mining, machine learning 솔루션으로 Classification, Clustering 등을 지원. 국내 어니컴에서 주로 개발&lt;br /&gt;&lt;br /&gt;Presto&lt;br /&gt;&lt;a href=&quot;https://github.com/facebook/presto&quot; target=&quot;_blank&quot;&gt;https://github.com/facebook/presto&lt;/a&gt;&lt;br /&gt;Facebook에서 만든 플랫폼으로 HDFS에 저장된 데이터를 질의를 이용하여 분석을 지원하는 플랫폼으로 정확한 결과 값이 아닌 근사치 값을 반환하면서 처리 성능을 빠르게 한 플랫폼이다. 단독으로 사용되기 보다는 Hive의 보완재로 사용되고 있다.&lt;br /&gt;&lt;br /&gt;YARN&lt;br /&gt;&lt;a href=&quot;http://hadoop.apache.org/&quot; target=&quot;_blank&quot;&gt;http://hadoop.apache.org/&lt;/a&gt;&lt;br /&gt;Hadoop의 차세대 컴퓨팅 플랫폼으로 분산된 서버의 리소스 관리와 이들 리소스에 컴퓨팅 모듈을 실행하는 기능을 제공한다. Map/Reduce의 JobTracker, TaskTracker도 hadoop 2.0이 되면서 YARN 기반으로 동작하며 많은 데이터 처리 플랫폼이 YARN을 지원하거나 지원할 예정이다.&lt;br /&gt;&lt;br /&gt;Whirr&lt;br /&gt;&lt;a href=&quot;http://whirr.apache.org/&quot; target=&quot;_blank&quot;&gt;http://whirr.apache.org/&lt;/a&gt;&lt;br /&gt;EC2와 같은 클라우드 환경에 분산 처리 플랫폼을 배포, 설정, 실행 등을 지원하는 플랫폼&lt;br /&gt;&lt;br /&gt;Ambari&lt;br /&gt;&lt;a href=&quot;http://ambari.apache.org/&quot; target=&quot;_blank&quot;&gt;http://ambari.apache.org/&lt;/a&gt;&lt;br /&gt;Web 기반 Hadoop 관리 솔루션으로 HDFS, MapReduce, Hive, HBase, ZooKeeper, Oozie, Pig, Sqoop 등을 관리할 수 있다.&lt;br /&gt;&lt;br /&gt;Flamingo&lt;br /&gt;&lt;a href=&quot;http://sourceforge.net/projects/hadoop-manager/&quot; target=&quot;_blank&quot;&gt;http://sourceforge.net/projects/hadoop-manager/&lt;/a&gt;&lt;br /&gt;Workflow, HDFS Browser, Hive Query Editor 등을 웹 GUI 환경으로 제공하는 솔루션으로 국내 개발 솔루션&lt;br /&gt;&lt;br /&gt;Tadpole DB Hub&lt;br /&gt;&lt;a href=&quot;https://sites.google.com/site/tadpolefordb/&quot; target=&quot;_blank&quot;&gt;https://sites.google.com/site/tadpolefordb/&lt;/a&gt;&lt;br /&gt;다양한 데이터베이스(PostgreSQL, MySQL, Hive, Tajo 등)의 데이터를 하나의 웹 인터페이스에서 관리할 수 있는 기능 제공. 국내 개발 솔루션&lt;br /&gt;&lt;br /&gt;giraph &lt;br /&gt;&lt;a href=&quot;http://giraph.apache.org/&quot; target=&quot;_blank&quot;&gt;http://giraph.apache.org/&lt;/a&gt;&lt;br /&gt;BSP 개념을 이용하여 네트워크 분석을 분산된 환경에서 처리할 수 있도록 한 플랫폼으로 출시는 꽤 되었지만 관심을 못 가졌는데 올해는 좀 볼 예정&lt;br /&gt;&lt;br /&gt;더 있으면 알려주세요.&lt;br /&gt;&amp;nbsp;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>lucene_hadoop</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/484</guid>
			<comments>http://www.jaso.co.kr/484#entry484comment</comments>
			<pubDate>Mon, 06 Jan 2014 11:35:10 +0900</pubDate>
		</item>
		<item>
			<title>hoya 간단 테스트</title>
			<link>http://www.jaso.co.kr/483</link>
			<description>&lt;span style=&quot;color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none;&quot;&gt;tajo를 yarn 기반으로 올리기 위해 간단하게 hoya 테스트 해보았습니다.&lt;br /&gt;tajo는 다음 두가지 모드로 yarn을 지원할 예정인데 hoya는 첫번째 모드를 위해 사용해보려고 합니다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;mode-1: yarn을 이용하여 tajo master, worker를 실행하여 클러스터를 구성후 계속해서 사용. 즉, 클러스터 실행 또는 특정 서버 장애시 다른 서버에 재시작하는 기능으로 yarn을 사용(hbase 클러스터에서 yarn을 사용하는 방식과 동일)&lt;/li&gt;&lt;li&gt;mode-2: 매번 질의시 마다 tajo 클러스터를 구성하고 질의 종료 시 자원을 회수하는 방식, Elastic MapReduce와 비슷한 방식&amp;nbsp; &lt;/li&gt;&lt;/ul&gt;&lt;/span&gt;&lt;br style=&quot;color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);&quot;&gt;&lt;span style=&quot;color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none;&quot;&gt;hbase의 경우 hmaster와 regionserver가 항상 실행되어 있어야 하는 특성을 가지고 있는 클러스터입니다.&lt;/span&gt;&lt;br style=&quot;color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);&quot;&gt;&lt;br style=&quot;color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);&quot;&gt;&lt;span style=&quot;color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none;&quot;&gt;hoya를 이용하여 yarn에 hmaster, regionserver를 실행하고 hmaster, regionserver를 kill 하면 yarn이 자동으로 해당 데몬을 다시 실행해줍니다.&lt;/span&gt;&lt;span class=&quot;text_exposed_show&quot; style=&quot;display: inline; color: rgb(51, 51, 51); font-family: &#039;lucida grande&#039;, tahoma, verdana, arial, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 17.940000534057617px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);&quot;&gt;&lt;br /&gt;&lt;br /&gt;실행 방법은 hdfs에 hbase.tar를 넣어 두고 hbase의 환경 설정은 hoya 명령을 실행할 로컬 서버의 특정 디렉토리나 hdfs의 특정 디렉토리에 hbase-site.xml에 저장하고 hoya 명령을 실행하면 hbase.tar를 yarn 로컬에 복사하여 압축을 해제하고 conf를 배포한 다음에 bin/hbase 명령을 실행하는 방식입니다.&lt;br /&gt;&lt;br /&gt;여기서 주의해야 할 사항은 hbase.tar의 lib내에 hadoop 관련 라이브러리가 hbase를 실행할 hadoop의 라이브러리와 버전이 동일해야 합니다. 저는 hbase 다운로드, 압축해제, lib의 hadoop 관련 jar 교체, 다시 hbase.tar로 묶어서 사용했습니다.&lt;br /&gt;&lt;br /&gt;사용 명령은 다음과 같았습니다.&lt;br /&gt;&lt;br /&gt;bin/hoya create cl1 \&lt;br /&gt;--role master 1\&lt;br /&gt;--role worker 1\&lt;br /&gt;--manager 127.0.0.1:8032 --filesystem hdfs://127.0.0.1:9000 --zkhosts localhost \&lt;br /&gt;&lt;span&gt;--image hdfs://127.0.0.1:9000/user/&lt;/span&gt;&lt;wbr&gt;babokim/hbase/hbase.tar \&lt;br /&gt;&lt;span&gt;--appconf file:///Users/babokim/&lt;/span&gt;&lt;wbr&gt;&lt;span&gt;Downloads/hbase-0.96.0-hadoop2/&lt;/span&gt;&lt;wbr&gt;conf \&lt;br /&gt;--roleopt master app.infoport 8880 \&lt;br /&gt;--roleopt master jvm.heap 128 \&lt;br /&gt;--roleopt master env.MALLOC_ARENA_MAX 4 \&lt;br /&gt;--roleopt worker app.infoport 8881 \&lt;br /&gt;--roleopt worker jvm.heap 128&lt;br /&gt;&lt;br /&gt;&lt;/span&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>All</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/483</guid>
			<comments>http://www.jaso.co.kr/483#entry483comment</comments>
			<pubDate>Thu, 26 Dec 2013 19:47:01 +0900</pubDate>
		</item>
		<item>
			<title>SQL-On-Hadoop 이란?</title>
			<link>http://www.jaso.co.kr/482</link>
			<description>앞의 블로그 글(SQL on Hadoop 100배, 200배 성능의 진실, &lt;a href=&quot;http://www.jaso.co.kr/480&quot; target=&quot;_blank&quot;&gt;http://www.jaso.co.kr/480&lt;/a&gt;)에 갑작스럽게 SQL-On-Hadoop이라는 용어를 언급하면서 바로 성능이야기를 했는데 순서로 보면 SQL-On-Hadoop을 먼저 소개하고 성능 이야기를 해야 하는데 성능 컬럼을 쓸때 외국 회사들의 마케팅에 욱해서 급하게 쓰면서 제대로된 소개를 못했는데 이번 컬럼에서는 SQL-On-Hadoop에 대해서 살펴보기로 한다. &lt;br /&gt;&lt;br /&gt;SQL-On-Hadoop은 다음 그림과 같이&amp;nbsp; 데이터 파일을 Hadoop에 저장하고 이 데이터를 SQL을 이용하여 분산된 환경에서 질의를 실행하여 결과를 반환하는 시스템을 말한다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;imageblock center&quot; style=&quot;text-align: center; clear: both;&quot;&gt;&lt;img src=&quot;http://www.jaso.co.kr/attach/1/1206927860.png&quot; alt=&quot;사용자 삽입 이미지&quot; height=&quot;305&quot; width=&quot;308&quot; /&gt;&lt;/div&gt;SQL-On-Hadoop 시스템이 집중 조명 받는 이유는 다음과 같은 이유때문이다.&lt;br /&gt;(http://www.slideshare.net/gruter/tech-planet-final)&lt;br /&gt;- MapReduce의 한계&lt;br /&gt;&amp;nbsp; . 데이터 처리 모델상의 한계 (관계형 처리를 위해 고안된 것이 아님)&lt;br /&gt;&amp;nbsp; &amp;nbsp; Map -&amp;gt; Shuffle -&amp;gt; Reduce&lt;br /&gt;&amp;nbsp; . Pig, Hive는 MapReduce가 제공하는 기능 이상의 최적화 불가능&lt;br /&gt;&amp;nbsp; . 느린 속도 (초기화 및 스케쥴링 지연)&lt;br /&gt;&amp;nbsp; &amp;nbsp; MapReduce가 느린 것이 아님, 하둡 구현이 느린 것&lt;br /&gt;&lt;br /&gt;- 높은 learning curve 및 Legacy 시스템들과 호환성 문제&lt;br /&gt;&amp;nbsp; . MapReduce는 어렵고, 개발 노력이 많이 들고, 성능 보장이 어려움&lt;br /&gt;&amp;nbsp; &amp;nbsp; MapReduce의 직접 사용은 점차 줄고 있음&lt;br /&gt;&amp;nbsp; . HiveQL != SQL&lt;br /&gt;&lt;br /&gt;- Ad-hoc 질의에 대한 속도 문제로 DBMS 병행 사용 불가피&lt;br /&gt;&amp;nbsp; . 부담이 큰 ETL의 문제 (HDFS &amp;lt;-&amp;gt; DBMS)&lt;br /&gt;&amp;nbsp; . 추가적인 스토리지 공간 필요, 비싼 DBMS 라이센스 비용의 벽&lt;br /&gt;&lt;br /&gt;즉, 기존 Hadoop MapReduce 플랫폼의 단점과 사용자에게 익숙하면서 기존 시스템과 통합이 쉬운 SQL 기반으로 Hadoop의 데이터를 처리하는 방식인 SQL-On-Hadoop이 각광받고 있는 것이다. &lt;br /&gt;SQL-On-Hadoop 시스템으로는 Tajo, Hive, Impala, Presto 등이 있으며 서로 다른 목표와 시스템 구성이 되어 있어 사용 및 선택에 있어 주의가 필요하다. 각 시스템들의 특징은 다음과 같다.&lt;br /&gt;&lt;br /&gt;- Hive&lt;br /&gt;가장 많이 사용하는 SQL-On-Hadoop 시스템, HiveQL이라고 하는 SQL과 거의 비슷한 문법 사용, 메타스토어에 테이블 정보, 컬럼 정보 등 저장. SQL을 MapReduce로 변환하여 실행.&lt;br /&gt;장점은 MapReduce의 확정성, 안정성 등의 특징을 모두 가지고 있으며 많은 기업에서 사용하고 있으며 다양한 도구들과 연동 가능&lt;br /&gt;단점은 MapReduce의 단점이기도 한 map -&amp;gt; reduce task 의 셔플 데이터가 디스크 기반으로 동작하며 job과 job 사이에도 hdfs 파일을 이용하여 동작하기 때문에 성능이 느림&lt;br /&gt;&lt;br /&gt;- Stinger&lt;br /&gt;별도의 솔루션이라기보다는 hive를 개선하는 프로젝트로 hotonworks 주도로 진행되고 있음. 다음 개선 사항을 중심으로 진행&lt;br /&gt;. 실행계획개선: join, order by 등에서 실행 계획을 개선함로써 mapreduce job의 갯수를 줄이거나 분산 처리 효과를 올려 성능을 개선&lt;br /&gt;. 파일 포맷 개선: ORC라고 하는 좀더 개선된 columnar file formart을 만들고 이를 지원. ORC는 string 타입인 경우 내부에 dictionary 기반 저장 방식을 이용하여, 컬럼별 압축 포맷을 다르게 줄 수 있어 데이터 타입에 최적화된 압축을 할 수 있고, 다양한 메타 정보를 저장함으로써 읽기에 최적화된 파일 포맷. 단점은 쓰기 성능이 좋지 않음&lt;br /&gt;. 실행엔진 tez 적용: 기존 hive는 mapreduce를 실행엔진으로 사용하고 있어 mapreduce의 장단점을 그대로 가지고 있어 성능 개선하는데 한계가 있음. tez라고 apache incubation 프로젝트로 진행 중인 DAG 기반의 컴퓨팅 엔진을 적용하여 효율적인 실행계획과 컴퓨팅 작업을 수행하는 것을 목표로 함. hive 질의의 모든 operation을 tez 기반으로 다시 만들어야 하기 때문에 출시까지는 시간이 다소 소요될 것으로 예상&lt;br /&gt;Hotonworks에서 주도적으로 개발하고 있으며 Hotonworks의 주력 제품으로 만들기 위해 노력중&lt;br /&gt;&lt;br /&gt;- Impala: hdfs 또는 hbase에 저장된 데이터 HiveQL을 이용하여 처리, 메타스토어는 Hive의 메타스토어 이용&lt;br /&gt;장점은 MapReduce 방식이 아닌 자체 질의 실행 엔진을 가지고 있어 MapReduce의 셔플 오버헤드가 없으며, 실행계획이 다단계로 구성되는 경우 각 단계를 중간 데이터를 HDFS에 저장하지 않기 때문에 질의 실행 성능이 뛰어나다.&lt;br /&gt;단점은 중간 데이터를 메모리에 모두 가지고 있기 때문에 중간 데이터가 메모리 크기를 넘어서는 질의는 실행할 수 없으며 실제 질의를 실행해야지만 에러 여부를 파악할 수 있다는 것이다. ETL 용도보다는 Interactive Analysis 용도로 적합하다고 할 수 있다.&lt;br /&gt;아파치 라이센스의 오픈소스이기는 하지만 Cloudera에서 코드에 대한 제어권을 가지고 있어 오픈소스 커뮤니티가 형성되어 있지는 않다.&lt;br /&gt;&lt;br /&gt;- Apache Drill: 빠른 질의 응답성능을 목표로 개발되고 있는 아파치 오픈소스로 진행되고 있다. 현재 1.0이 릴리즈 되었지만 분산 환경에서 실행되지 않으며 한대에서 질의 파서, 질의 실행 계획 수립, 질의 실행 등의 작업이 수행되는 수준&lt;br /&gt;MapR이 주도적으로 개발하고 있으며 질의 계획 및 최적화 계층을 Optiq라는 외부 솔루션에 의존&lt;br /&gt;&lt;br /&gt;- Presto: Facebook에서 최근 공개한 오픈 소스로 Approximate Aggregation 이라고 하여 아주 큰 데이터에 대해 정확한 결과 값보다는 통계적 기법을 이용하여 예상치를 제공하는 방식으로 질의 성능을 향상 시킨 솔루션이다. Facebook에서는 Hive를 주로 사용하고 정확하지는 않지만 빠른 응답성이 필요한 업무에 Presto를 사용하고 있다고 한다.&lt;br /&gt;Presto는 현재 초기 버전으로 지원하는 질의도 많지 않으며 성능도 Impala와 비슷하거나 다소 떨어지는 것으로 테스트 되고 있다.&lt;br /&gt;&lt;br /&gt;- &lt;a href=&quot;http://tajo.incubator.apache.org&quot; target=&quot;_blank&quot;&gt;Tajo&lt;/a&gt;: Tajo는 하둡 기반의 대용량 데이터웨어 하우스 시스템을 목표로 하는 솔루션으로 현재 아파치 인큐베이션 프로젝트로 진행 중인 프로젝트이다. &lt;br /&gt;Tajo는 분산된 저장소에 저장된 데이터를 SQL 질의를 분산 실행 시켜 빠르게 데이터를 처리하는 기능을 제공하는 플랫폼이다. &lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;imageblock center&quot; style=&quot;text-align: center; clear: both;&quot;&gt;&lt;img src=&quot;http://www.jaso.co.kr/attach/1/1139294735.png&quot; alt=&quot;사용자 삽입 이미지&quot; height=&quot;284&quot; width=&quot;450&quot; /&gt;&lt;/div&gt;&lt;br /&gt;Tajo의 목표는 다음 두가지 요구사항을 모두 만족시키는 시스템이다.&lt;br /&gt;- Hive와 같이 아주 큰 데이터를 이용하여&amp;nbsp; 1 ~ 2 시간 이상 실행되는 질의에 대한 지원&lt;br /&gt;- 다양한 성능 개선을 통해 Hive 대비 상대적으로 빠른 질의 응답성을 지원함으로써 Interactive Analysis 질의 지원&lt;br /&gt;이 두가지 목표를 위해 Tajo는 다양한 최적화와 데이터베이스에서 사용하는 다양한 기법을 사용하고 있다. &lt;br /&gt;&amp;nbsp;Tajo의 장점은 다음과 같다.&lt;br /&gt;- Hive 대비 헤비 질의는 3 ~ 5배 정도, 짧은 질의는 수십배 정도의 빠른 질의 성능&lt;br /&gt;- 표준 SQL을 지원하는 것과 동시에 많이 사용하는 Hive 질의도 동시에 지원하며 메타 스토어도 자체 메타 스토어와 Hive 메타 스토어 모두를 지원하여 기존 시스템을 쉽게 Tajo로 전환 가능 &lt;br /&gt;- 하나의 플랫폼으로 Long time query, interactive analysis query 모두 지원&lt;br /&gt;- 활발한 커뮤니티&lt;br /&gt;- 한국어 Q&amp;amp;A 및 기술 지원 가능, 사용 시 적극적인 커뮤니티 지원(한국 커미터가 지원 ㅋ)&lt;br /&gt;&lt;br /&gt;Tajo의 단점은 다음과 같다.&lt;br /&gt;- 최근 출시된 프로젝트로 검증이 안되었다.&lt;br /&gt;- 일부 함수, 질의 문법 등 미지원&lt;br /&gt;&lt;br /&gt;너무 긴 글을 쓰다보니 뭔가 결론을 내려야 할 것 같은데 앞의 글과 같은 결론으로 대신하고자 한다. 각 솔루션의 특/장점을 잘 파악하여 자신의 환경, 요구사항에 맞는 솔루션을 선택하는 것이 중요하다.&lt;br /&gt;&lt;fieldset style=&quot;margin:20px 0px 20px 0px;padding:5px;&quot;&gt;&lt;legend&gt;&lt;span&gt;&lt;strong&gt;크리에이티브 커먼즈 라이센스&lt;/strong&gt;&lt;/span&gt;&lt;/legend&gt;&lt;!--Creative Commons License--&gt;&lt;div style=&quot;float: left; width: 88px; margin-top: 3px;&quot;&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width: 0&quot; src=&quot;http://i.creativecommons.org/l/by-nc-nd/2.0/kr/88x31.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 92px; margin-top: 3px; text-align: justify;&quot;&gt;이 저작물은 &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; target=_blank&gt;크리에이티브 커먼즈 코리아 저작자표시-비영리-변경금지 2.0 대한민국 라이센스&lt;/a&gt;에 따라 이용하실 수 있습니다.
			&lt;!-- Creative Commons License--&gt;
			&lt;!-- &lt;rdf:RDF xmlns=&quot;http://web.resource.org/cc/&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;&gt;
			&lt;Work rdf:about=&quot;&quot;&gt;
			&lt;license rdf:resource=&quot;http://creativecommons.org/licenses/by-nc-nd/2.0/kr/&quot; /&gt;
			&lt;/Work&gt;
			&lt;License rdf:about=&quot;http://creativecommons.org/licenses/by-nc-nd/&quot;&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Reproduction&quot;/&gt;
			&lt;permits rdf:resource=&quot;http://web.resource.org/cc/Distribution&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Notice&quot;/&gt;
			&lt;requires rdf:resource=&quot;http://web.resource.org/cc/Attribution&quot;/&gt;&lt;prohibits rdf:resource=&quot;http://web.resource.org/cc/CommercialUse&quot;/&gt;&lt;/License&gt;&lt;/rdf:RDF&gt; --&gt;&lt;/div&gt;&lt;/fieldset&gt;</description>
			<category>Dev_diary</category>
			<author>(김형준)</author>
			<guid>http://www.jaso.co.kr/482</guid>
			<comments>http://www.jaso.co.kr/482#entry482comment</comments>
			<pubDate>Fri, 22 Nov 2013 22:59:30 +0900</pubDate>
		</item>
	</channel>
</rss>
